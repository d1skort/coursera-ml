{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считайте таблицу с признаками из файла features.csv с помощью кода, приведенного выше. Удалите признаки, связанные с итогами матча (они помечены в описании данных как отсутствующие в тестовой выборке)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = pd.read_csv('features.csv', index_col='match_id')\n",
    "features.drop(\n",
    "    ['start_time', 'duration', 'tower_status_radiant', 'tower_status_dire', \n",
    "     'barracks_status_dire', 'barracks_status_radiant'],\n",
    "    axis=1,\n",
    "    inplace=True\n",
    ")\n",
    "matches = features.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте выборку на наличие пропусков с помощью функции count(), которая для каждого столбца показывает число заполненных значений. Много ли пропусков в данных? Запишите названия признаков, имеющих пропуски, и попробуйте для любых двух из них дать обоснование, почему их значения могут быть пропущены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_blood_time\n",
      "first_blood_team\n",
      "first_blood_player1\n",
      "first_blood_player2\n",
      "radiant_bottle_time\n",
      "radiant_courier_time\n",
      "radiant_flying_courier_time\n",
      "radiant_first_ward_time\n",
      "dire_bottle_time\n",
      "dire_courier_time\n",
      "dire_flying_courier_time\n",
      "dire_first_ward_time\n"
     ]
    }
   ],
   "source": [
    "counts = features.count()\n",
    "missing = counts[counts != matches]\n",
    "for name in missing.index:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замените пропуски на нули с помощью функции fillna(). На самом деле этот способ является предпочтительным для логистической регрессии, поскольку он позволит пропущенному значению не вносить никакого вклада в предсказание. Для деревьев часто лучшим вариантом оказывается замена пропуска на очень большое или очень маленькое значение — в этом случае при построении разбиения вершины можно будет отправить объекты с пропусками в отдельную ветвь дерева. Также есть и другие подходы — например, замена пропуска на среднее значение признака. Мы не требуем этого в задании, но при желании попробуйте разные подходы к обработке пропусков и сравните их между собой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for name in missing.index:\n",
    "    features[name].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какой столбец содержит целевую переменную? Запишите его название."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = features['radiant_win']\n",
    "features.drop('radiant_win', axis=1, inplace=True)\n",
    "\n",
    "X = features.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Забудем, что в выборке есть категориальные признаки, и попробуем обучить градиентный бустинг над деревьями на имеющейся матрице \"объекты-признаки\". Зафиксируйте генератор разбиений для кросс-валидации по 5 блокам (KFold), не забудьте перемешать при этом выборку (shuffle=True), поскольку данные в таблице отсортированы по времени, и без перемешивания можно столкнуться с нежелательными эффектами при оценивании качества. Оцените качество градиентного бустинга (GradientBoostingClassifier) с помощью данной кросс-валидации, попробуйте при этом разное количество деревьев (как минимум протестируйте следующие значения для количества деревьев: 10, 20, 30). Долго ли настраивались классификаторы? Достигнут ли оптимум на испытанных значениях параметра n_estimators, или же качество, скорее всего, продолжит расти при дальнейшем его увеличении?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed for n_estimaters=10: 0:00:07.524770\n",
      "Time elapsed for n_estimaters=10: 0:00:07.718111\n",
      "Time elapsed for n_estimaters=10: 0:00:07.569763\n",
      "Time elapsed for n_estimaters=10: 0:00:07.467916\n",
      "Time elapsed for n_estimaters=10: 0:00:07.993642\n",
      "Time elapsed for n_estimaters=20: 0:00:12.774479\n",
      "Time elapsed for n_estimaters=20: 0:00:13.120844\n",
      "Time elapsed for n_estimaters=20: 0:00:12.451629\n",
      "Time elapsed for n_estimaters=20: 0:00:12.936708\n",
      "Time elapsed for n_estimaters=20: 0:00:11.951211\n",
      "Time elapsed for n_estimaters=30: 0:00:20.319237\n",
      "Time elapsed for n_estimaters=30: 0:00:19.426570\n",
      "Time elapsed for n_estimaters=30: 0:00:19.691805\n",
      "Time elapsed for n_estimaters=30: 0:00:18.293860\n",
      "Time elapsed for n_estimaters=30: 0:00:18.350798\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "scores = defaultdict(list)\n",
    "for n_estimators in (10, 20, 30):\n",
    "    clf = GradientBoostingClassifier(n_estimators=n_estimators)\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        start_time = datetime.datetime.now()\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        probs = clf.predict_proba(X_test)\n",
    "        \n",
    "        print('Time elapsed for n_estimaters={}: {}'.format(n_estimators, datetime.datetime.now() - start_time))\n",
    "        \n",
    "        scores[n_estimators].append(roc_auc_score(y_test, probs[:, 1]))\n",
    "    scores[n_estimators] = np.mean(scores[n_estimators])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {10: 0.66480789207044266,\n",
       "             20: 0.68200053631530844,\n",
       "             30: 0.6898704609090146})"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцените качество логистической регрессии (sklearn.linear_model.LogisticRegression с L2-регуляризацией) с помощью кросс-валидации по той же схеме, которая использовалась для градиентного бустинга. Подберите при этом лучший параметр регуляризации (C). Какое наилучшее качество у вас получилось? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_logistic_regression(X, y):\n",
    "    best_score = 0\n",
    "    best_c = 0\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    for C in np.logspace(-3, 0, num=5):\n",
    "        clf = LogisticRegression(penalty='l2', C=C)\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "            start_time = datetime.datetime.now()\n",
    "            clf.fit(X_train, y_train)\n",
    "            probs = clf.predict_proba(X_test)\n",
    "            print('Time elapsed for C={}: {}'.format(C, datetime.datetime.now() - start_time))\n",
    "        \n",
    "            score = roc_auc_score(y_test, probs[:, 1])\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_c = C\n",
    "    return best_score, best_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed for C=0.001: 0:00:01.390618\n",
      "Time elapsed for C=0.001: 0:00:01.710314\n",
      "Time elapsed for C=0.001: 0:00:01.725432\n",
      "Time elapsed for C=0.001: 0:00:01.446161\n",
      "Time elapsed for C=0.001: 0:00:01.470715\n",
      "Time elapsed for C=0.005623413251903491: 0:00:02.757079\n",
      "Time elapsed for C=0.005623413251903491: 0:00:02.301870\n",
      "Time elapsed for C=0.005623413251903491: 0:00:02.183077\n",
      "Time elapsed for C=0.005623413251903491: 0:00:02.242043\n",
      "Time elapsed for C=0.005623413251903491: 0:00:02.110328\n",
      "Time elapsed for C=0.03162277660168379: 0:00:02.335798\n",
      "Time elapsed for C=0.03162277660168379: 0:00:02.428356\n",
      "Time elapsed for C=0.03162277660168379: 0:00:02.480551\n",
      "Time elapsed for C=0.03162277660168379: 0:00:02.343630\n",
      "Time elapsed for C=0.03162277660168379: 0:00:02.391013\n",
      "Time elapsed for C=0.1778279410038923: 0:00:02.599273\n",
      "Time elapsed for C=0.1778279410038923: 0:00:02.378384\n",
      "Time elapsed for C=0.1778279410038923: 0:00:02.544275\n",
      "Time elapsed for C=0.1778279410038923: 0:00:02.526753\n",
      "Time elapsed for C=0.1778279410038923: 0:00:02.601003\n",
      "Time elapsed for C=1.0: 0:00:02.381340\n",
      "Time elapsed for C=1.0: 0:00:02.505315\n",
      "Time elapsed for C=1.0: 0:00:02.541759\n",
      "Time elapsed for C=1.0: 0:00:02.533543\n",
      "Time elapsed for C=1.0: 0:00:02.442290\n"
     ]
    }
   ],
   "source": [
    "best_score, best_c = score_logistic_regression(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.72315131659748866, 0.031622776601683791)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score, best_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среди признаков в выборке есть категориальные, которые мы использовали как числовые, что вряд ли является хорошей идеей. Категориальных признаков в этой задаче одиннадцать: lobby_type и r1_hero, r2_hero, ..., r5_hero, d1_hero, d2_hero, ..., d5_hero. Уберите их из выборки, и проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. Изменилось ли качество? Чем вы можете это объяснить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorial_features = [\n",
    "    'lobby_type',\n",
    "    'r1_hero',\n",
    "    'r2_hero',\n",
    "    'r3_hero',\n",
    "    'r4_hero',\n",
    "    'r5_hero',\n",
    "    'd1_hero',\n",
    "    'd2_hero',\n",
    "    'd3_hero',\n",
    "    'd4_hero',\n",
    "    'd5_hero'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = features.drop(categorial_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed for C=0.001: 0:00:01.250531\n",
      "Time elapsed for C=0.001: 0:00:02.006933\n",
      "Time elapsed for C=0.001: 0:00:01.970099\n",
      "Time elapsed for C=0.001: 0:00:01.590641\n",
      "Time elapsed for C=0.001: 0:00:01.232115\n",
      "Time elapsed for C=0.005623413251903491: 0:00:02.180531\n",
      "Time elapsed for C=0.005623413251903491: 0:00:01.980709\n",
      "Time elapsed for C=0.005623413251903491: 0:00:01.941825\n",
      "Time elapsed for C=0.005623413251903491: 0:00:01.961808\n",
      "Time elapsed for C=0.005623413251903491: 0:00:01.721294\n",
      "Time elapsed for C=0.03162277660168379: 0:00:03.170221\n",
      "Time elapsed for C=0.03162277660168379: 0:00:03.096205\n",
      "Time elapsed for C=0.03162277660168379: 0:00:02.378050\n",
      "Time elapsed for C=0.03162277660168379: 0:00:02.354792\n",
      "Time elapsed for C=0.03162277660168379: 0:00:02.274782\n",
      "Time elapsed for C=0.1778279410038923: 0:00:02.545826\n",
      "Time elapsed for C=0.1778279410038923: 0:00:02.200557\n",
      "Time elapsed for C=0.1778279410038923: 0:00:02.262658\n",
      "Time elapsed for C=0.1778279410038923: 0:00:02.108043\n",
      "Time elapsed for C=0.1778279410038923: 0:00:02.196627\n",
      "Time elapsed for C=1.0: 0:00:02.950211\n",
      "Time elapsed for C=1.0: 0:00:03.091012\n",
      "Time elapsed for C=1.0: 0:00:02.510539\n",
      "Time elapsed for C=1.0: 0:00:02.213688\n",
      "Time elapsed for C=1.0: 0:00:02.292361\n"
     ]
    }
   ],
   "source": [
    "best_score, best_c = score_logistic_regression(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7211168571078661, 0.005623413251903491)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score, best_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На предыдущем шаге мы исключили из выборки признаки rM_hero и dM_hero, которые показывают, какие именно герои играли за каждую команду. Это важные признаки — герои имеют разные характеристики, и некоторые из них выигрывают чаще, чем другие. Выясните из данных, сколько различных идентификаторов героев существует в данной игре (вам может пригодиться фукнция unique или value_counts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    }
   ],
   "source": [
    "heroes = categorial_features[:]\n",
    "heroes.remove('lobby_type')\n",
    "unique_heroes = set()\n",
    "for hero_feature_name in heroes:\n",
    "    unique_heroes.update(features[hero_feature_name].unique())\n",
    "print(len(unique_heroes))\n",
    "unique_heroes = list(unique_heroes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся подходом \"мешок слов\" для кодирования информации о героях. Пусть всего в игре имеет N различных героев. Сформируем N признаков, при этом i-й будет равен нулю, если i-й герой не участвовал в матче; единице, если i-й герой играл за команду Radiant; минус единице, если i-й герой играл за команду Dire. Ниже вы можете найти код, который выполняет данной преобразование. Добавьте полученные признаки к числовым, которые вы использовали во втором пункте данного этапа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_pick = np.zeros((features.shape[0], 108))\n",
    "for i, match_id in enumerate(features.index):\n",
    "    for p in range(5):\n",
    "        r_hero_code = features.ix[match_id, 'r%d_hero' % (p+1)]\n",
    "        X_pick[i, unique_heroes.index(r_hero_code)] = 1\n",
    "        \n",
    "        d_hero_code = features.ix[match_id, 'd%d_hero' % (p+1)]\n",
    "        X_pick[i, unique_heroes.index(d_hero_code)] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.hstack((X, X_pick))\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. Какое получилось качество? Улучшилось ли оно? Чем вы можете это объяснить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed for C=0.001: 0:00:03.195017\n",
      "Time elapsed for C=0.001: 0:00:03.284971\n",
      "Time elapsed for C=0.001: 0:00:02.852921\n",
      "Time elapsed for C=0.001: 0:00:02.856956\n",
      "Time elapsed for C=0.001: 0:00:02.978540\n",
      "Time elapsed for C=0.005623413251903491: 0:00:03.755062\n",
      "Time elapsed for C=0.005623413251903491: 0:00:03.748924\n",
      "Time elapsed for C=0.005623413251903491: 0:00:03.654423\n",
      "Time elapsed for C=0.005623413251903491: 0:00:03.894805\n",
      "Time elapsed for C=0.005623413251903491: 0:00:03.644014\n",
      "Time elapsed for C=0.03162277660168379: 0:00:03.961687\n",
      "Time elapsed for C=0.03162277660168379: 0:00:04.510821\n",
      "Time elapsed for C=0.03162277660168379: 0:00:04.898055\n",
      "Time elapsed for C=0.03162277660168379: 0:00:04.282829\n",
      "Time elapsed for C=0.03162277660168379: 0:00:04.018072\n",
      "Time elapsed for C=0.1778279410038923: 0:00:04.122521\n",
      "Time elapsed for C=0.1778279410038923: 0:00:04.350694\n",
      "Time elapsed for C=0.1778279410038923: 0:00:04.718328\n",
      "Time elapsed for C=0.1778279410038923: 0:00:04.379893\n",
      "Time elapsed for C=0.1778279410038923: 0:00:04.548750\n",
      "Time elapsed for C=1.0: 0:00:04.184675\n",
      "Time elapsed for C=1.0: 0:00:04.157938\n",
      "Time elapsed for C=1.0: 0:00:04.395376\n",
      "Time elapsed for C=1.0: 0:00:04.079335\n",
      "Time elapsed for C=1.0: 0:00:04.584063\n"
     ]
    }
   ],
   "source": [
    "best_score, best_c = score_logistic_regression(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.75781959002067301, 1.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score, best_c # после добавления `мешка слов` качество улучшилось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте предсказания вероятностей победы команды Radiant для тестовой выборки с помощью лучшей из изученных моделей (лучшей с точки зрения AUC-ROC на кросс-валидации). Убедитесь, что предсказанные вероятности адекватные — находятся на отрезке [0, 1], не совпадают между собой (т.е. что модель не получилась константной)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('features_test.csv', index_col='match_id')\n",
    "X_test.drop([\n",
    "    'start_time',\n",
    "    'lobby_type'\n",
    "], axis=1, inplace=True)\n",
    "matches = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts = X_test.count()\n",
    "missing = counts[counts != matches]\n",
    "for name in missing.index:\n",
    "    X_test[name].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_pick = np.zeros((X_test.shape[0], 108))\n",
    "for i, match_id in enumerate(X_test.index):\n",
    "    for p in range(5):\n",
    "        r_hero_code = X_test.ix[match_id, 'r%d_hero' % (p+1)]\n",
    "        X_pick[i, unique_heroes.index(r_hero_code)] = 1\n",
    "        \n",
    "        d_hero_code = X_test.ix[match_id, 'd%d_hero' % (p+1)]\n",
    "        X_pick[i, unique_heroes.index(d_hero_code)] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test.drop([\n",
    "    'r1_hero',\n",
    "    'r2_hero',\n",
    "    'r3_hero',\n",
    "    'r4_hero',\n",
    "    'r5_hero',\n",
    "    'd1_hero',\n",
    "    'd2_hero',\n",
    "    'd3_hero',\n",
    "    'd4_hero',\n",
    "    'd5_hero'\n",
    "], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_merged = np.hstack((X_test, X_pick))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_merged_scaled = scaler.fit_transform(X_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty='l2', C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs = clf.predict_proba(X_merged_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.83633895,  0.77901248,  0.20100047, ...,  0.22564408,\n",
       "        0.62264571,  0.41819582])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17177,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = {'match_id': [], 'radiant_win': []}\n",
    "for i, match_id in enumerate(X_test.index):\n",
    "    res['match_id'].append(match_id)\n",
    "    res['radiant_win'].append(probs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(res)\n",
    "res_df.set_index('match_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res_df.to_csv('final-results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
